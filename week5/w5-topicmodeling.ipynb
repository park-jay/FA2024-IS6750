{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* We learned how to count N-grams (i.e., sequences of N words such as unigrams (N=1) and bigrams (N=2)) by tokenizing the text.\n",
    ">* But we faced a problem of counting N-grams when there are unnecessary or meaningless tokens after tokenization.\n",
    ">* Therefore, we needed a further processing to remove stopwords (i.e., function words) and punctuations. \n",
    ">* The last step was to convert the text into lowercase to avoid counting the same words in different cases as different words. For instance, 'Eat' and 'eat' should be treated as the same word. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* In this week, we will learn topic modeling, one of the unsupervised learning techniques, to extract topics from the text. \n",
    ">* Topic modeling is a type of statistical model to discover abstract topics that occur in a collection of documents. \n",
    ">* We will use the Latent Dirichlet Allocation (LDA) model, one of the most popular topic modeling techniques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "is6750",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
